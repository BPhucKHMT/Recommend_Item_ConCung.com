
import polars as pl
import pandas as pd
import numpy as np
import pickle
from tqdm import tqdm
import gc
import os
import math

def evaluate(df_final, k=10, gt_path="data/final_groundtruth.pkl", history_path="data/table/purchase_data.parquet"):
    print(f"\n>>> EVALUATION (New Product Discovery Mode) @ K={k}")
    
    # --------------------------------------------------------------------------
    # B∆Ø·ªöC 1: LOAD HISTORY (ƒê·ªÇ L·ªåC B·ªé M√ìN C≈® KH·ªéI GROUND TRUTH)
    # --------------------------------------------------------------------------
    print(">> Loading Training History (to filter re-purchases)...")
    hist_dict = {}
    try:
        # Load transaction log (ch·ª©a l·ªãch s·ª≠ train)
        # Ch·ªâ l·∫•y c·ªôt customer_id v√† item_id
        if os.path.exists(history_path):
            df_hist = pl.scan_parquet(history_path).select([
                pl.col("customer_id").cast(pl.String),
                pl.col("item_id").cast(pl.String).str.strip_chars()
            ])
            
            # Gom nh√≥m th√†nh Dict {user: set(items)}
            # D√πng Polars groupby -> aggregation -> to_pandas -> zip ƒë·ªÉ t·∫°o dict c·ª±c nhanh
            # (Nhanh h∆°n iter_rows r·∫•t nhi·ªÅu)
            hist_agg = (
                df_hist.group_by("customer_id")
                .agg(pl.col("item_id"))
                .collect()
            )
            
            # Convert to dict lookup
            # customer_id -> list[item_id]
            uids = hist_agg["customer_id"].to_list()
            items_list = hist_agg["item_id"].to_list()
            
            # Chuy·ªÉn list th√†nh set ngay l·∫≠p t·ª©c ƒë·ªÉ tra c·ª©u O(1)
            hist_dict = {u: set(i) for u, i in zip(uids, items_list)}
            
            print(f"   -> Loaded History for {len(hist_dict)} users.")
            del df_hist, hist_agg, uids, items_list
            gc.collect()
        else:
            print(f"‚ö†Ô∏è Warning: History file {history_path} not found. Evaluation will act like standard Recall.")
    except Exception as e:
        print(f"‚ùå Error loading history: {e}")

    # --------------------------------------------------------------------------
    # B∆Ø·ªöC 2: CHU·∫®N B·ªä PREDICTIONS
    # --------------------------------------------------------------------------
    print(">> Aggregating predictions...")
    preds_lf = (
        df_final.lazy()
        .sort(["customer_id", "pred_score"], descending=[False, True])
        .group_by("customer_id")
        .agg(pl.col("item_id").cast(pl.String).head(k).alias("pred_items"))
    )
    
    # --------------------------------------------------------------------------
    # B∆Ø·ªöC 3: LOAD GROUND TRUTH (FIXED & OPTIMIZED)
    # --------------------------------------------------------------------------
    print(">> Loading Ground Truth (Direct Pandas -> Polars)...")
    try:
        # Load tr·ª±c ti·∫øp file pickle (ƒëang l√† pandas DataFrame)
        pd_gt = pd.read_pickle(gt_path)
        
        # ƒê·ªïi t√™n c·ªôt 'item_id' trong GT th√†nh 'gt_items' ƒë·ªÉ tr√°nh tr√πng t√™n khi join
        if "item_id" in pd_gt.columns:
            pd_gt.rename(columns={"item_id": "gt_items"}, inplace=True)
            
        # Convert th·∫≥ng sang Polars (c·ª±c nhanh, zero-copy n·∫øu c√≥ th·ªÉ)
        df_gt = pl.from_pandas(pd_gt)
        
        # X√≥a bi·∫øn pandas ngay l·∫≠p t·ª©c ƒë·ªÉ gi·∫£i ph√≥ng RAM
        del pd_gt
        gc.collect()

    except Exception as e:
        print(f"‚ùå Error loading GT: {e}")
        return {}

    # Ki·ªÉm tra xem c√≥ d·ªØ li·ªáu kh√¥ng
    if df_gt.height == 0: return {}

    # ƒê·ªìng b·ªô Schema ID v·ªõi df_final (√©p ki·ªÉu customer_id cho kh·ªõp)
    pred_schema_id = df_final.schema["customer_id"]
    if df_gt.schema["customer_id"] != pred_schema_id:
        df_gt = df_gt.with_columns(pl.col("customer_id").cast(pred_schema_id))
    # --------------------------------------------------------------------------
    # B∆Ø·ªöC 4: JOIN DATA
    # --------------------------------------------------------------------------
    print(">> Joining Predictions with Ground Truth...")
    merged_df = preds_lf.join(df_gt.lazy(), on="customer_id", how="inner").collect()
    
    n_users_matched = merged_df.height
    if n_users_matched == 0:
        print("‚ö†Ô∏è Kh√¥ng c√≥ user n√†o tr√πng kh·ªõp!")
        return {"precision": 0, "recall": 0, "ndcg": 0}

    # --------------------------------------------------------------------------
    # B∆Ø·ªöC 5: T√çNH METRICS (C√ì L·ªåC HISTORY)
    # --------------------------------------------------------------------------
    print("   -> Calculating metrics (Logic: Only evaluate on NEW items)...")
    
    total_precision = 0.0
    total_recall = 0.0
    total_ndcg = 0.0
    
    valid_users_count = 0 # ƒê·∫øm s·ªë user th·ª±c s·ª± mua m√≥n m·ªõi
    
    # Cache IDCG
    idcg_table = {}
    for n_rel in range(1, k + 1):
        idcg_table[n_rel] = sum(1.0 / math.log2(i + 2) for i in range(n_rel))
    
    # C·∫ßn l·∫•y c·∫£ customer_id ƒë·ªÉ tra c·ª©u history
    rows_iter = merged_df.select(["customer_id", "pred_items", "gt_items"]).iter_rows()
    
    for uid, pred_items, gt_items in tqdm(rows_iter, total=n_users_matched, desc="Scoring"):
        if not gt_items: continue
        
        # 1. L·∫•y Ground Truth th√¥
        gt_set_raw = set(gt_items)
        
        # 2. L·∫•y History Items c·ªßa user n√†y
        # (L∆∞u √Ω: uid t·ª´ merged_df ƒëang ·ªü d·∫°ng ƒë√∫ng c·ªßa pred_schema, c·∫ßn cast v·ªÅ str ƒë·ªÉ tra dict n·∫øu dict key l√† str)
        hist_items = hist_dict.get(str(uid), set())
        
        # 3. [QUAN TR·ªåNG] L·ªçc b·ªè m√≥n ƒë√£ mua kh·ªèi GT
        # ƒê√¢y l√† t·∫≠p h·ª£p nh·ªØng m√≥n M·ªöI kh√°ch mua trong t∆∞∆°ng lai
        gt_set_new = gt_set_raw - hist_items
        
        # N·∫øu kh√°ch ch·ªâ to√†n mua l·∫°i ƒë·ªì c≈© -> B·ªè qua, kh√¥ng t√≠nh v√†o ƒë√°nh gi√°
        # V√¨ model discovery kh√¥ng c√≥ nhi·ªám v·ª• ƒëo√°n vi·ªác mua l·∫°i.
        if not gt_set_new: 
            continue
            
        valid_users_count += 1
            
        hits = 0
        dcg = 0.0
        
        # 4. T√≠nh to√°n Metrics tr√™n t·∫≠p GT_NEW
        for i, item in enumerate(pred_items):
            # Item ƒëo√°n ƒë√∫ng ph·∫£i n·∫±m trong t·∫≠p M·ªöI
            if item in gt_set_new:
                hits += 1
                dcg += 1.0 / math.log2(i + 2)
        
        # Precision: Bao nhi√™u % item g·ª£i √Ω l√† ƒë√∫ng (v√† l√† m√≥n m·ªõi)
        total_precision += (hits / k)
        
        # Recall: G·ª£i √Ω ƒë∆∞·ª£c bao nhi√™u % trong t·ªïng s·ªë m√≥n M·ªöI kh√°ch ƒë√£ mua
        # M·∫´u s·ªë l√† len(gt_set_new), KH√îNG PH·∫¢I len(gt_set_raw)
        total_recall += (hits / len(gt_set_new))
        
        # NDCG
        ideal_num = min(len(gt_set_new), k)
        if ideal_num > 0:
            idcg = idcg_table.get(ideal_num, 0.0)
            if idcg > 0:
                total_ndcg += (dcg / idcg)

    # Clean up
    del merged_df
    gc.collect()

    if valid_users_count == 0:
        print("‚ö†Ô∏è Warning: No users bought NEW items in the test set.")
        return {"precision": 0, "recall": 0, "ndcg": 0}

    avg_prec = total_precision / valid_users_count
    avg_recall = total_recall / valid_users_count
    avg_ndcg = total_ndcg / valid_users_count
    
    print("-" * 60)
    print(f"üìä DISCOVERY REPORT @ K={k}")
    print(f"   (Evaluated on {valid_users_count} users who bought NEW items)")
    print("-" * 60)
    print(f"   - Precision (New Items): {avg_prec:.4%}")
    print(f"   - Recall (New Items):    {avg_recall:.4%}")
    print(f"   - NDCG (New Items):      {avg_ndcg:.4%}")
    print("-" * 60)
    
    return {"precision": avg_prec, "recall": avg_recall, "ndcg": avg_ndcg}