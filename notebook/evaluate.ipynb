{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac5d2e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import json\n",
    "import json \n",
    "\n",
    "predict = json.load(open('final_prediction_v4.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e148c45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "groudtruth = pickle.load(open('data/final_groundtruth.pkl', 'rb'))\n",
    "import polars as pl \n",
    "groundtruth = pl.from_pandas(groudtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e61f1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2337685</td>\n",
       "      <td>[0020010000305]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7934799</td>\n",
       "      <td>[0020010000438]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2052333</td>\n",
       "      <td>[3513000000064, 2403000000004, 3460000000018, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6548920</td>\n",
       "      <td>[6701000000004]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>368770</td>\n",
       "      <td>[5420000000003, 5420000000002, 1371000000002, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id                                            item_id\n",
       "0      2337685                                    [0020010000305]\n",
       "1      7934799                                    [0020010000438]\n",
       "2      2052333  [3513000000064, 2403000000004, 3460000000018, ...\n",
       "3      6548920                                    [6701000000004]\n",
       "4       368770  [5420000000003, 5420000000002, 1371000000002, ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groudtruth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6c37648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl \n",
    "\n",
    "\n",
    "history = pl.read_parquet('data/table/purchase_new.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00b079fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_predict_to_polars(predict_dict):\n",
    "    records = []\n",
    "    for customer_id, item_list in predict_dict.items():\n",
    "        for item_id in item_list:\n",
    "            records.append({\"customer_id\": customer_id, \"item_id\": item_id})\n",
    "    return pl.DataFrame(records)\n",
    "\n",
    "predict_df = convert_predict_to_polars(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba8cd404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>customer_id</th><th>item_id</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;17212&quot;</td><td>&quot;3774000000003&quot;</td></tr><tr><td>&quot;17212&quot;</td><td>&quot;4690000000001&quot;</td></tr><tr><td>&quot;17212&quot;</td><td>&quot;1512000000004&quot;</td></tr><tr><td>&quot;17212&quot;</td><td>&quot;3773000000004&quot;</td></tr><tr><td>&quot;17212&quot;</td><td>&quot;2803000000013&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ customer_id â”† item_id       â”‚\n",
       "â”‚ ---         â”† ---           â”‚\n",
       "â”‚ str         â”† str           â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 17212       â”† 3774000000003 â”‚\n",
       "â”‚ 17212       â”† 4690000000001 â”‚\n",
       "â”‚ 17212       â”† 1512000000004 â”‚\n",
       "â”‚ 17212       â”† 3773000000004 â”‚\n",
       "â”‚ 17212       â”† 2803000000013 â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e961c35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(df_final, k=10, gt_path=\"data/final_groundtruth.pkl\", history_path=\"data/table/purchase_new.parquet\", filter_history=True):\n",
    "    print(f\"\\n>>> EVALUATION (New Product Discovery Mode) @ K={k}\")\n",
    "    \n",
    "    # --------------------------------------------------------------------------\n",
    "    # BÆ¯á»šC 1: LOAD HISTORY (Äá»‚ Lá»ŒC Bá» MÃ“N CÅ¨ KHá»I GROUND TRUTH)\n",
    "    # --------------------------------------------------------------------------\n",
    "    print(\">> Loading Training History (to filter re-purchases)...\")\n",
    "    hist_dict = {}\n",
    "    try:\n",
    "        # Load transaction log (chá»©a lá»‹ch sá»­ train)\n",
    "        # Chá»‰ láº¥y cá»™t customer_id vÃ  item_id\n",
    "        if os.path.exists(history_path):\n",
    "            df_hist = pl.scan_parquet(history_path).select([\n",
    "                pl.col(\"customer_id\").cast(pl.String),\n",
    "                pl.col(\"item_id\").cast(pl.String).str.strip_chars()\n",
    "            ])\n",
    "            \n",
    "            # Gom nhÃ³m thÃ nh Dict {user: set(items)}\n",
    "            # DÃ¹ng Polars groupby -> aggregation -> to_pandas -> zip Ä‘á»ƒ táº¡o dict cá»±c nhanh\n",
    "            # (Nhanh hÆ¡n iter_rows ráº¥t nhiá»u)\n",
    "            hist_agg = (\n",
    "                df_hist.group_by(\"customer_id\")\n",
    "                .agg(pl.col(\"item_id\"))\n",
    "                .collect()\n",
    "            )\n",
    "            \n",
    "            # Convert to dict lookup\n",
    "            # customer_id -> list[item_id]\n",
    "            uids = hist_agg[\"customer_id\"].to_list()\n",
    "            items_list = hist_agg[\"item_id\"].to_list()\n",
    "            \n",
    "            # Chuyá»ƒn list thÃ nh set ngay láº­p tá»©c Ä‘á»ƒ tra cá»©u O(1)\n",
    "            hist_dict = {u: set(i) for u, i in zip(uids, items_list)}\n",
    "            \n",
    "            print(f\"   -> Loaded History for {len(hist_dict)} users.\")\n",
    "            del df_hist, hist_agg, uids, items_list\n",
    "            gc.collect()\n",
    "        else:\n",
    "            print(f\"âš ï¸ Warning: History file {history_path} not found. Evaluation will act like standard Recall.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading history: {e}\")\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # BÆ¯á»šC 2: CHUáº¨N Bá»Š PREDICTIONS\n",
    "    # --------------------------------------------------------------------------\n",
    "    print(\">> Aggregating predictions...\")\n",
    "    preds_lf = (\n",
    "        df_final.lazy()\n",
    "        .group_by(\"customer_id\")\n",
    "        .agg(pl.col(\"item_id\").cast(pl.String).head(k).alias(\"pred_items\"))\n",
    "    )\n",
    "    \n",
    "    # --------------------------------------------------------------------------\n",
    "    # BÆ¯á»šC 3: LOAD GROUND TRUTH (FIXED & OPTIMIZED)\n",
    "    # --------------------------------------------------------------------------\n",
    "    print(\">> Loading Ground Truth (Direct Pandas -> Polars)...\")\n",
    "    try:\n",
    "        # Load trá»±c tiáº¿p file pickle (Ä‘ang lÃ  pandas DataFrame)\n",
    "        pd_gt = pd.read_pickle(gt_path)\n",
    "        \n",
    "        # Äá»•i tÃªn cá»™t 'item_id' trong GT thÃ nh 'gt_items' Ä‘á»ƒ trÃ¡nh trÃ¹ng tÃªn khi join\n",
    "        if \"item_id\" in pd_gt.columns:\n",
    "            pd_gt.rename(columns={\"item_id\": \"gt_items\"}, inplace=True)\n",
    "            \n",
    "        # Convert tháº³ng sang Polars (cá»±c nhanh, zero-copy náº¿u cÃ³ thá»ƒ)\n",
    "        df_gt = pl.from_pandas(pd_gt)\n",
    "        \n",
    "        # XÃ³a biáº¿n pandas ngay láº­p tá»©c Ä‘á»ƒ giáº£i phÃ³ng RAM\n",
    "        del pd_gt\n",
    "        gc.collect()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading GT: {e}\")\n",
    "        return {}\n",
    "\n",
    "    # Kiá»ƒm tra xem cÃ³ dá»¯ liá»‡u khÃ´ng\n",
    "    if df_gt.height == 0: return {}\n",
    "\n",
    "    # Äá»“ng bá»™ Schema ID vá»›i df_final (Ã©p kiá»ƒu customer_id cho khá»›p)\n",
    "    pred_schema_id = df_final.schema[\"customer_id\"]\n",
    "    if df_gt.schema[\"customer_id\"] != pred_schema_id:\n",
    "        df_gt = df_gt.with_columns(pl.col(\"customer_id\").cast(pred_schema_id))\n",
    "    # --------------------------------------------------------------------------\n",
    "    # BÆ¯á»šC 4: JOIN DATA\n",
    "    # --------------------------------------------------------------------------\n",
    "    print(\">> Joining Predictions with Ground Truth...\")\n",
    "    merged_df = preds_lf.join(df_gt.lazy(), on=\"customer_id\", how=\"inner\").collect()\n",
    "    \n",
    "    n_users_matched = merged_df.height\n",
    "    if n_users_matched == 0:\n",
    "        print(\"âš ï¸ KhÃ´ng cÃ³ user nÃ o trÃ¹ng khá»›p!\")\n",
    "        return {\"precision\": 0, \"recall\": 0, \"ndcg\": 0}\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # BÆ¯á»šC 5: TÃNH METRICS (CÃ“ Lá»ŒC HISTORY)\n",
    "    # --------------------------------------------------------------------------\n",
    "    print(\"   -> Calculating metrics (Logic: Only evaluate on NEW items)...\")\n",
    "    \n",
    "    total_precision = 0.0\n",
    "    total_recall = 0.0\n",
    "    total_ndcg = 0.0\n",
    "    \n",
    "    valid_users_count = 0 # Äáº¿m sá»‘ user thá»±c sá»± mua mÃ³n má»›i\n",
    "    \n",
    "    # Cache IDCG\n",
    "    idcg_table = {}\n",
    "    for n_rel in range(1, k + 1):\n",
    "        idcg_table[n_rel] = sum(1.0 / math.log2(i + 2) for i in range(n_rel))\n",
    "    \n",
    "    # Cáº§n láº¥y cáº£ customer_id Ä‘á»ƒ tra cá»©u history\n",
    "    rows_iter = merged_df.select([\"customer_id\", \"pred_items\", \"gt_items\"]).iter_rows()\n",
    "    \n",
    "    for uid, pred_items, gt_items in tqdm(rows_iter, total=n_users_matched, desc=\"Scoring\"):\n",
    "        if not gt_items: continue\n",
    "        \n",
    "        # 1. Láº¥y Ground Truth thÃ´\n",
    "        gt_set_raw = set(gt_items)\n",
    "        \n",
    "        # 2. Láº¥y History Items cá»§a user nÃ y\n",
    "        # (LÆ°u Ã½: uid tá»« merged_df Ä‘ang á»Ÿ dáº¡ng Ä‘Ãºng cá»§a pred_schema, cáº§n cast vá» str Ä‘á»ƒ tra dict náº¿u dict key lÃ  str)\n",
    "        hist_items = hist_dict.get(str(uid), set())\n",
    "        \n",
    "        # 3. [QUAN TRá»ŒNG] Lá»c bá» mÃ³n Ä‘Ã£ mua khá»i GT\n",
    "        # ÄÃ¢y lÃ  táº­p há»£p nhá»¯ng mÃ³n Má»šI khÃ¡ch mua trong tÆ°Æ¡ng lai\n",
    "        if filter_history:\n",
    "            gt_set_new = gt_set_raw - hist_items\n",
    "        else:\n",
    "            gt_set_new = gt_set_raw\n",
    "        \n",
    "        # Náº¿u khÃ¡ch chá»‰ toÃ n mua láº¡i Ä‘á»“ cÅ© -> Bá» qua, khÃ´ng tÃ­nh vÃ o Ä‘Ã¡nh giÃ¡\n",
    "        # VÃ¬ model discovery khÃ´ng cÃ³ nhiá»‡m vá»¥ Ä‘oÃ¡n viá»‡c mua láº¡i.\n",
    "        if not gt_set_new: \n",
    "            continue\n",
    "            \n",
    "        valid_users_count += 1\n",
    "            \n",
    "        hits = 0\n",
    "        dcg = 0.0\n",
    "        \n",
    "        # 4. TÃ­nh toÃ¡n Metrics trÃªn táº­p GT_NEW\n",
    "        for i, item in enumerate(pred_items):\n",
    "            # Item Ä‘oÃ¡n Ä‘Ãºng pháº£i náº±m trong táº­p Má»šI\n",
    "            if item in gt_set_new:\n",
    "                hits += 1\n",
    "                dcg += 1.0 / math.log2(i + 2)\n",
    "        \n",
    "        # Precision: Bao nhiÃªu % item gá»£i Ã½ lÃ  Ä‘Ãºng (vÃ  lÃ  mÃ³n má»›i)\n",
    "        total_precision += (hits / k)\n",
    "        \n",
    "        # Recall: Gá»£i Ã½ Ä‘Æ°á»£c bao nhiÃªu % trong tá»•ng sá»‘ mÃ³n Má»šI khÃ¡ch Ä‘Ã£ mua\n",
    "        # Máº«u sá»‘ lÃ  len(gt_set_new), KHÃ”NG PHáº¢I len(gt_set_raw)\n",
    "        total_recall += (hits / len(gt_set_new))\n",
    "        \n",
    "        # NDCG\n",
    "        ideal_num = min(len(gt_set_new), k)\n",
    "        if ideal_num > 0:\n",
    "            idcg = idcg_table.get(ideal_num, 0.0)\n",
    "            if idcg > 0:\n",
    "                total_ndcg += (dcg / idcg)\n",
    "\n",
    "    # Clean up\n",
    "    del merged_df\n",
    "    gc.collect()\n",
    "\n",
    "    if valid_users_count == 0:\n",
    "        print(\"âš ï¸ Warning: No users bought NEW items in the test set.\")\n",
    "        return {\"precision\": 0, \"recall\": 0, \"ndcg\": 0}\n",
    "\n",
    "    avg_prec = total_precision / valid_users_count\n",
    "    avg_recall = total_recall / valid_users_count\n",
    "    avg_ndcg = total_ndcg / valid_users_count\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(f\"ğŸ“Š DISCOVERY REPORT @ K={k}\")\n",
    "    print(f\"   (Evaluated on {valid_users_count} users who bought NEW items)\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"   - Precision (New Items): {avg_prec:.4%}\")\n",
    "    print(f\"   - Recall (New Items):    {avg_recall:.4%}\")\n",
    "    print(f\"   - NDCG (New Items):      {avg_ndcg:.4%}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    return {\"precision\": avg_prec, \"recall\": avg_recall, \"ndcg\": avg_ndcg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80d53726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> EVALUATION (New Product Discovery Mode) @ K=10\n",
      ">> Loading Training History (to filter re-purchases)...\n",
      "   -> Loaded History for 2569978 users.\n",
      ">> Aggregating predictions...\n",
      ">> Loading Ground Truth (Direct Pandas -> Polars)...\n",
      ">> Joining Predictions with Ground Truth...\n",
      "   -> Calculating metrics (Logic: Only evaluate on NEW items)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 644970/644970 [00:02<00:00, 220782.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "ğŸ“Š DISCOVERY REPORT @ K=10\n",
      "   (Evaluated on 644970 users who bought NEW items)\n",
      "------------------------------------------------------------\n",
      "   - Precision (New Items): 9.4217%\n",
      "   - Recall (New Items):    27.0051%\n",
      "   - NDCG (New Items):      14.6334%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.09421725041444907,\n",
       " 'recall': 0.2700512879409111,\n",
       " 'ndcg': 0.146334394707241}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import os\n",
    "import math\n",
    "\n",
    "evaluate(predict_df, k=10, gt_path=\"data/final_groundtruth.pkl\", history_path=\"data/table/purchase_new.parquet\", filter_history=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8184f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df = pl.read_parquet('data/table/item_data.parquet')\n",
    "# join predict with sale status\n",
    "predict_df = predict_df.join(item_df.select([pl.col('item_id'), pl.col('sale_status')]), on='item_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05adbcb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sale_status</th><th>item_id</th></tr><tr><td>i32</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>348</td></tr><tr><td>1</td><td>573</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ sale_status â”† item_id â”‚\n",
       "â”‚ ---         â”† ---     â”‚\n",
       "â”‚ i32         â”† u32     â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 0           â”† 348     â”‚\n",
       "â”‚ 1           â”† 573     â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so luong unique item_id co sale status 1 va 0 la \n",
    "predict_df.group_by('sale_status').agg(pl.col('item_id').n_unique()).sort('sale_status')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
